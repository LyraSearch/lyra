---
title: Web Crawler
description: Import your website contents into Orama Cloud.
editUrl: false
---
import { ShowcaseImage } from 'starlight-showcases';
import { Aside, Steps } from '@astrojs/starlight/components';

If you are looking for an alternative data source to integrate with Orama Cloud, you can use our <a href="https://cloud.orama.com/indexes/create/from-website" target="_blank">Web Crawler</a> to index the contents of your website. This is particularly useful when you want to index a public website that does not provide an API.

<Aside type="danger">
The Web Crawler is a tool meant to be used to index the contents of a website you own. <br />
**Do not use it** to crawl websites you do not own or have permission to crawl. 
</Aside>

<Aside type="caution">
Be careful when using this data source, as it can be resource-intensive and may not be suitable for all use cases. The Web Crawler is a tool that can be used to index the contents of a public website in few clicks. However, it can lead to unpredictable results if not used correctly. 
</Aside>

---

### Usage

The Web Crawler data source allows you to index the contents of a website by providing the URL of the website you want to index. Once started, it will then crawl through the website links, index the contents of the pages, and make them available for search.

The Web Crawler can be configured to exclude certain URL paths from being indexed. This can be useful if you want to exclude certain parts of your website from being indexed, such as admin pages or pages with sensitive information.

### Limitations

There are some limitations to the Web Crawler, such as the number of pages that can be indexed and the time it takes to index a website. If you have a large website with many pages, it may take some time for the Web Crawler to index all the pages.

More over, the Web Crawler may not be able to index all the pages of a website due to the website's structure, non-standard HTML semantic, or other limitations like website configuration or `robots.txt` file.

Client side rendered websites, websites with dynamic content, or websites with complex JavaScript may not be fully indexed by the Web Crawler.

## Creating an index

<Steps>
<ol>
    <li>
      <p class="pl-10">Create a new index in the [dashboard](https://cloud.orama.com) by selecting the data source "Web Crawler".</p>
      <p class="pl-10">Insert an index name and your website homepage URL.</p>
      <img
        src="/cloud/guides/web-crawler/orama-crawler-new-index.png"
        alt="Create a new index using the Web Crawler data source"
        class="mx-10"
      />
    </li>
    <li>
      <p class="pl-10">Click **Create index** and proceed to the crawler configuration.</p>
      <p class="pl-10">In this section, you can optionally configure how the data should be scraped.</p>
      <img
        src="/cloud/guides/web-crawler/orama-crawler-index-configuration.png"
        alt="Create a new index using the Web Crawler data source"
        class="mx-10"
      />
      <p class="pl-10">**Excluding URL with path patterns**: <br />you can exclude certain URLs from being indexed by providing a list of URL path patterns to exclude, using <a href="https://regex101.com/" target="_blank">Regular Expressions</a>.</p>
      <p class="pl-10">**Facet property**: <br />you can configure the facet property for the indexed pages, based on the URL structure, that can be used to categorize and filter your **search documents**.</p>
      <p class="pl-10">**Deploy frequency**: <br />Finally, you can set the deploy frequency to determine how often the Web Crawler should re-index your website.</p>
      <br />
    </li>
    <li>
      <p class="pl-10">Click <b>Save and Deploy</b> and the Web Crawler will do the heavy lifting. It will crawl through your website links and index the contents of all the pages.</p>
      <img
        src="/cloud/guides/web-crawler/orama-crawler-deploy-completed.png"
        alt="Create a new index using the Web Crawler data source"
        class="mx-10"
      />
    </li>
    <li>
      <p class="pl-10">Done! ðŸŽ‰ You just indexed your website data. If you want, you can test your index by clicking the **Test now** button.</p>
    </li>
</ol>
</Steps>

### Troubleshooting

Firstly, check out the logs displayed in the dashboard to see if there are any errors. 

Verify that the website URL is correct and accessible. Also, make sure that the index configuration is correct, including the `Excluding URL path patterns` option. If you are unsure about the URL patterns to exclude, you can test them using a <a href="https://regex101.com/" target="_blank">Regular Expression tester</a>.

Large websites with many pages can take a long time to index. In some cases, the Web Crawler may not be able to index all the pages due to the website's structure or limitations.

If you are still having trouble, please reach out to our [Slack](https://orama.to/slack) for support.

### Integrating into your app

Now that you have your index deployed, you can start using it in your app.

Orama Cloud provides Official SDKs for JavaScript, Swift, Kotlin, PHP and Python. You can use it to query your data (and much more).

To learn more about the SDKs, check out the [documentation](/cloud/integrating-orama-cloud/official-sdk).

---
title: Embeddings Generation
description: Learn how to automatically generate embeddings from your data at deployment.
editUrl: false
---
import { ShowcaseText } from 'starlight-showcases';
import { Aside } from '@astrojs/starlight/components';

With Orama Cloud, you can automatically generate embeddings from your data at deployment.

This guide will walk you through the process of creating embeddings using the **Orama Native Embeddings** or **OpenAI** model. We plan to support additional models in the near future.

## What are text embeddings?

Text embeddings are numerical representations of text that allow computers to understand the meaning and relationships between words, enabling applications like semantic search, machine translation, and sentiment analysis.

In recent months, embeddings have gained popularity as they form the foundation of semantic search, which is crucial in developing generative AI experiences like ChatGPT, Google Bard, and others.

Orama is a hybrid database capable of storing various types of data. It specializes in search capabilities, and its support for vector search enables semantic search among large sets of embeddings, which are presented as vectors.

For a deeper understanding of text embeddings, the Tensorflow website offers a fantastic explanation. It can be accessed [here](https://www.tensorflow.org/text/guide/word_embeddings).

## Automatic Embeddings Generation

Creating text embeddings from a given text or set of texts can be complex. However, Orama Cloud simplifies this process by enabling automatic generation of these embeddings each time you deploy a new index. This makes it remarkably easy to conduct semantic searches through your data at a remarkable speed.

Not only Orama Cloud will take care of embedding generation, but it will also apply **NLP-based chunking** on your data, making sure that large documents are split into smaller, semantically meaningful chunks within a specific number of tokens.
This will ensure that even for large texts, the LLM used to generate embeddings will have full context and won't cut off the text in the middle of a sentence when the token limit is reached.

## Using Orama AI

To perform vector and hybrid searches on your data using the **Orama AI** (Orama's native embeddings), **no configuration is necessary**.

When creating or editing an index, simply select an Orama embedding model (e.g. `orama/gte-small`) and the searchable properties you would like to use for the embeddings generation. This will automatically generate embeddings from your data.

<img
  src='/cloud/guides/automatic-embeddings-generation/orama-native-embeddings.png'
  alt='Automatic embeddings generation via Orama Native Embeddings'
/>

## Using OpenAI

If you prefer to use OpenAI's models, the following section will guide you through the necessary configuration.

### Connecting to OpenAI

<Aside type="note">
To use this feature, you will need an OpenAI account and an OpenAI API Key. <br />Make sure to visit the [Developer Tools](https://cloud.orama.com/developer-tools) section and configure your private API Key.
</Aside>

Before you can start generating embeddings, you need to connect to OpenAI. This requires adding an OpenAI API Key to Orama Cloud.

We will encrypt this API Key and store it securely. For safety reasons, we recommend creating a new API Key specifically for Orama Cloud from the OpenAI dashboard.

As soon as you have your OpenAI API Key ready, you can add it to Orama Cloud by going to [Developer Tools](https://cloud.orama.com/developer-tools), and selecting "**OpenAI API key**" from the left menu.

<img
  src='/cloud/guides/automatic-embeddings-generation/automatic-embeddings-generation.png'
  alt='Adding OpenAI API Key to Orama Cloud'
/>

After adding your API key, you won't be able to view it again for security reasons. While you can delete it, this is not recommended as all operations dependent on vector search will cease to function. Alternatively, you may choose to replace it with a new key.

<img
  src='/cloud/guides/automatic-embeddings-generation/open-ai-api-key.png'
  alt='Your OpenAI API Key'
/>

### Creating the Embeddings

You can now create a new index by going to [Orama Cloud dashboard](https://cloud.orama.com/indexes), if you don't have one yet. Depending on your use case, you will need to select the right Data Source to import your data (check out our guide on [Data Sources](/cloud/data-sources/introduction-to-data-sources) to learn more about the available options).

When creating an index, the embedding generation is automatically enabled. You can select the Large Language Model (LLM) you would like to use for the embeddings generation. 

<img
  src='/cloud/guides/automatic-embeddings-generation/orama-native-embeddings.png'
  alt='Automatic embeddings generation via Orama Native Embeddings'
/>

## Querying the embeddings

Now that you have your embeddings distributed on Orama Cloud, you can use the [official JavaScript client](/cloud/integrating-orama-cloud/javascript-sdk) to perform vector search on them.

Read more about performing vector search on Orama Cloud [here](/cloud/performing-search/vector-search).

<ShowcaseText
  entries={[
    {
      href: 'https://cloud.orama.com',
      title: 'Performing vector search',
      description: 'Learn more how to perform vector search on Orama Cloud.',
    },
  ]}
/>

## Pricing

The automatic embeddings generation feature is included in all Orama Cloud plans with **no limits**. 

When using an **Orama AI** model, the embeddings generation is included in the flat rate.

When using <a href="https://openai.com/" target="_blank">OpenAI</a>, you will be required to provide your own **API Key**. Orama Cloud will not charge you for the embeddings generation, but you will be billed by OpenAI for the usage of their models.

For more precise pricing, please refer to the official [pricing page](https://orama.com/pricing).

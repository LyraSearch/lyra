/* IMPORTANT
 * This snapshot file is auto-generated, but designed for humans.
 * It should be checked into source control and tracked carefully.
 * Re-generate by setting TAP_SNAPSHOT=1 and running tests.
 * Make sure to inspect the output below.  Do not ignore changes!
 */
'use strict'
exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in danish > Should tokenize and stem correctly in danish-O1 1`] = `
Array [
  "sovn",
  "svar",
  "ting",
  "prov",
  "mislyk",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in danish > Should tokenize and stem correctly in danish-O2 1`] = `
Array [
  "bagt",
  "smakag",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in dutch > Should tokenize and stem correctly in dutch-O1 1`] = `
Array [
  "klein",
  "koei",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in dutch > Should tokenize and stem correctly in dutch-O2 1`] = `
Array [
  "taart",
  "gemaakt",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english > Should tokenize and stem correctly in english-O1 1`] = `
Array [
  "the",
  "quick",
  "brown",
  "fox",
  "jump",
  "over",
  "lazi",
  "dog",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english > Should tokenize and stem correctly in english-O2 1`] = `
Array [
  "i",
  "bake",
  "some",
  "cake",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english and allow duplicates > Should tokenize and stem correctly in english and allow duplicates-O1 1`] = `
Array [
  "thi",
  "is",
  "a",
  "test",
  "with",
  "test",
  "duplic",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in english and allow duplicates > Should tokenize and stem correctly in english and allow duplicates-O2 1`] = `
Array [
  "it'",
  "aliv",
  "it'",
  "aliv",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in finnish > Should tokenize and stem correctly in finnish-O1 1`] = `
Array [
  "uni",
  "vaike",
  "as",
  "test",
  "epaonnistuv",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in finnish > Should tokenize and stem correctly in finnish-O2 1`] = `
Array [
  "leivo",
  "keksej",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in french > Should tokenize and stem correctly in french-O1 1`] = `
Array [
  "voyon",
  "temp",
  "fait",
  "dehor",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in french > Should tokenize and stem correctly in french-O2 1`] = `
Array [
  "fait",
  "gateau",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in german > Should tokenize and stem correctly in german-O1 1`] = `
Array [
  "schlaf",
  "hart",
  "sach",
  "test",
  "fehlschlag",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in german > Should tokenize and stem correctly in german-O2 1`] = `
Array [
  "paar",
  "keks",
  "geback",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in italian > Should tokenize and stem correctly in italian-O1 1`] = `
Array [
  "cucin",
  "tort",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in italian > Should tokenize and stem correctly in italian-O2 1`] = `
Array [
  "dorm",
  "cos",
  "difficil",
  "quand",
  "test",
  "pass",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in norwegian > Should tokenize and stem correctly in norwegian-O1 1`] = `
Array [
  "kokt",
  "kak",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in norwegian > Should tokenize and stem correctly in norwegian-O2 1`] = `
Array [
  "sov",
  "vansk",
  "ting",
  "test",
  "mislykk",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in portuguese > Should tokenize and stem correctly in portuguese-O1 1`] = `
Array [
  "cozinh",
  "alguns",
  "bol",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in portuguese > Should tokenize and stem correctly in portuguese-O2 1`] = `
Array [
  "dorm",
  "e",
  "cois",
  "dificil",
  "test",
  "falh",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in russian > Should tokenize and stem correctly in russian-O1 1`] = `
Array [
  "приготов",
  "пирожн",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in russian > Should tokenize and stem correctly in russian-O2 1`] = `
Array [
  "спат",
  "трудн",
  "тест",
  "срабатыва",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in spanish > Should tokenize and stem correctly in spanish-O1 1`] = `
Array [
  "cocin",
  "pastel",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in spanish > Should tokenize and stem correctly in spanish-O2 1`] = `
Array [
  "dorm",
  "dificil",
  "prueb",
  "fall",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in swedish > Should tokenize and stem correctly in swedish-O1 1`] = `
Array [
  "lag",
  "kak",
]
`

exports[`tests/tokenizer.test.ts TAP Tokenizer Should tokenize and stem correctly in swedish > Should tokenize and stem correctly in swedish-O2 1`] = `
Array [
  "sov",
  "svar",
  "sak",
  "test",
  "misslyck",
]
`
